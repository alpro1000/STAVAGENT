# CLAUDE.md

> Guidelines for Claude Code (claude.ai/code) when working with this repository

**Version:** 2.3.0
**Last updated:** 2025-11-18

---

## ‚ö° QUICK REFERENCE (READ THIS FIRST!)

### üéØ Current Status (2025-11-18)
- **Phase:** 4 - Backend Infrastructure + Integration
- **Sprint:** Week 1 (Nov 6-13) - ‚úÖ 100% COMPLETE
- **Current:** Week 2 - Production Deployment (Nov 19-23)
- **Status:**
  - Backend infrastructure: ‚úÖ Ready (PostgreSQL, Redis, Celery)
  - Monolit integration: ‚úÖ Live (Smart fallback parser - Nov 18)
  - Monorepo strategy: ‚è≥ Pending decision
- **Production:**
  - Backend: https://concrete-agent.onrender.com (pending Nov 19 deployment)
  - Frontend: https://stav-agent.onrender.com

### üìã Essential Documents (Read Before Starting)
1. **DEVELOPMENT_PLAN.md** ‚≠ê **READ FIRST EVERY SESSION!**
   - Current priorities and tasks
   - Weekly sprint planning
   - Tech specs to create
   - Implementation guidelines

2. **CURRENT STATUS & DECISIONS** üÜï (Nov 18)
   - **CURRENT_STATUS.md** - Complete integration status + Week 2 decisions
   - **CORE_INTEGRATION.md** - Live integration with Monolit-Planner (Nov 18)

3. **INTEGRATION DOCUMENTS (Nov 16-18)** üîó
   - **INTEGRATION_CHECKLIST.md** - Complete 5-phase integration plan
   - **DOCKER_SETUP.md** - Docker & docker-compose configuration
   - **KB_TRAINING_GUIDE.md** - Knowledge base training with real data
   - **MONOLIT_TS_CLIENT.md** - TypeScript client for Monolit-Planner

4. **DEPLOYMENT_URLS.md** - Production environment info
5. **docs/TECH_SPECS/** - Detailed technical specifications (4 specs completed!)
6. **docs/COMPETITIVE_ANALYSIS_RozpocetPRO.md** (Part 1 & 2) - Market insights

### üöÄ Phase 4 Goals (Current - Week 1)
- [x] **Day 1 (Nov 6):** Tech specs created (4 files, ~39,000 lines)
- [x] **Day 2 (Nov 7):** PostgreSQL setup & Alembic migrations
  - ‚úÖ Dependencies installed (SQLAlchemy 2.0.36, asyncpg, Alembic)
  - ‚úÖ Alembic configured for async migrations
  - ‚úÖ Initial schema migration created (10 tables, 30+ indexes)
  - ‚è≥ Migration testing (pending Render PostgreSQL)
- [x] **Day 3 (Nov 7):** SQLAlchemy models & relationships ‚úÖ
  - ‚úÖ Created app/db/models/ structure (FastAPI best practice)
  - ‚úÖ Base model with UUIDMixin & TimestampMixin
  - ‚úÖ All 10 models created with full schema
  - ‚úÖ Business logic methods added
  - ‚úÖ All models tested and importing correctly
- [x] **Day 4 (Nov 7):** Redis integration (caching & sessions) ‚úÖ
  - ‚úÖ Added redis[hiredis]==5.0.1 to requirements.txt
  - ‚úÖ Redis configuration in config.py (DATABASE_URL, REDIS_URL, SESSION_TTL, CACHE_TTL)
  - ‚úÖ Created app/core/redis_client.py - Async Redis client with connection pooling
  - ‚úÖ Created app/core/session.py - Session management with TTL
  - ‚úÖ Created app/core/cache.py - Caching layer with decorators
  - ‚úÖ KnowledgeBaseCache for KROS/RTS/Perplexity caching
  - ‚úÖ Test suite created (tests/test_redis_integration.py)
- [x] **Day 5 (Nov 9):** Celery queue system (background jobs) ‚úÖ
  - ‚úÖ Added celery[redis]==5.4.0 to requirements.txt
  - ‚úÖ Celery configuration in config.py (CELERY_BROKER_URL, CELERY_RESULT_BACKEND, etc.)
  - ‚úÖ Created app/core/celery_app.py - Celery app with Redis broker (420 lines)
  - ‚úÖ Created app/tasks/ structure - Background task modules
  - ‚úÖ Created app/tasks/pdf_tasks.py - PDF parsing tasks (200+ lines)
  - ‚úÖ Created app/tasks/enrichment_tasks.py - Position enrichment tasks (170+ lines)
  - ‚úÖ Created app/tasks/audit_tasks.py - Audit execution tasks (190+ lines)
  - ‚úÖ Created app/tasks/maintenance.py - Periodic maintenance tasks (220+ lines)
  - ‚úÖ Created app/services/task_monitor.py - Task monitoring service (270+ lines)
  - ‚úÖ Celery Beat schedule configured (cleanup, KB updates)
  - ‚úÖ Test suite created (tests/test_celery_integration.py - 30+ tests)

### üóÑÔ∏è Database Schema (Day 2 Progress)
**10 Tables Created:**
1. ‚úÖ users - User accounts with auth
2. ‚úÖ projects - Project metadata & status
3. ‚úÖ project_documents - Uploaded files with full-text search
4. ‚úÖ positions - Budget line items
5. ‚úÖ audit_results - Multi-role audit outcomes
6. ‚úÖ chat_messages - Project chat history
7. ‚úÖ background_jobs - Celery task tracking
8. ‚úÖ budget_versions - Git-like version control
9. ‚úÖ knowledge_base_cache - Query result caching
10. ‚úÖ user_credentials - Encrypted credentials for paid services

**Key Features:**
- UUID primary keys with gen_random_uuid()
- JSONB columns for flexible metadata
- Full-text search (GIN index) for Czech documents
- Cascading deletes for data integrity
- Check constraints for enum validation
- 30+ indexes for query performance

### üîß SQLAlchemy Models (Day 3 Progress)
**10 ORM Models Created:**
1. ‚úÖ User (app/db/models/user.py) - Auth & roles
2. ‚úÖ Project (app/db/models/project.py) - Project tracking
3. ‚úÖ ProjectDocument (app/db/models/document.py) - File management
4. ‚úÖ Position (app/db/models/position.py) - Budget items
5. ‚úÖ AuditResult (app/db/models/audit.py) - AI audit outcomes
6. ‚úÖ ChatMessage (app/db/models/chat.py) - Conversations
7. ‚úÖ BackgroundJob (app/db/models/job.py) - Async tasks
8. ‚úÖ BudgetVersion (app/db/models/version.py) - Version control
9. ‚úÖ KnowledgeBaseCache (app/db/models/kb_cache.py) - Query caching
10. ‚úÖ UserCredential (app/db/models/credential.py) - Encrypted credentials

**Key Features:**
- Inherits from Base (UUID + timestamps)
- to_dict() / from_dict() methods
- Business logic methods (calculate_total, update_progress, etc.)
- Ready for relationships (commented out until all models complete)

### üî¥ Redis Integration (Day 4 Progress)
**3 Core Modules Created:**
1. ‚úÖ **RedisClient** (app/core/redis_client.py) - 550 lines
   - Async Redis operations with connection pooling
   - JSON serialization/deserialization
   - Key prefixing for namespacing ("concrete:")
   - Methods: get(), set(), delete(), exists(), expire(), incr(), decr()
   - Pattern operations: keys(), delete_pattern()
   - Health check and monitoring
   - Global instance: get_redis()

2. ‚úÖ **SessionManager** (app/core/session.py) - 370 lines
   - User session storage in Redis
   - Session TTL management (default 1 hour)
   - Session data: user_id, created_at, last_accessed, metadata
   - Methods: create_session(), get_session(), update_session(), delete_session()
   - Session validation and extension
   - Multi-device support: get_user_sessions(), delete_user_sessions()
   - Global instance: get_session_manager()

3. ‚úÖ **CacheManager** (app/core/cache.py) - 530 lines
   - General-purpose caching with TTL
   - Cache namespacing for isolation
   - Decorator for function result caching: @cache.cached(ttl=60)
   - **KnowledgeBaseCache** - Specialized KB caching:
     - KROS code lookup caching
     - RTS price caching
     - Perplexity query caching (24h TTL)
   - Cache statistics and cleanup
   - Global instances: get_cache(), get_kb_cache()

**Configuration Added (config.py):**
```python
DATABASE_URL: str  # PostgreSQL async connection
REDIS_URL: str     # Redis connection (default: localhost:6379)
SESSION_TTL: int   # Session TTL (default: 3600s = 1h)
CACHE_TTL: int     # Default cache TTL (default: 300s = 5min)
```

**Test Suite (tests/test_redis_integration.py):**
- 20+ tests covering all Redis operations
- Tests skip gracefully if Redis not available
- Test categories: RedisClient, SessionManager, CacheManager, KnowledgeBaseCache

### üîµ Redis & Celery (Phase 4 Infrastructure)

**‚úÖ CONFIRMED IN PRODUCTION:**

```bash
# Check requirements.txt
grep -E "redis|celery" requirements.txt
```

**Output:**
```
redis[hiredis]==5.0.1  # Redis client with C parser
celery[redis]==5.4.0   # Celery task queue with Redis broker
```

**Status:** ‚úÖ Both installed and configured
- Redis: Production-ready for sessions, caching, and message broker
- Celery: Production-ready for background jobs and task scheduling
- PostgreSQL: Production-ready (async with SQLAlchemy 2.0)

---

### üîµ Celery Queue System (Day 5 Progress)
**5 Core Modules Created:**
1. ‚úÖ **CeleryApp** (app/core/celery_app.py) - 420 lines
   - Celery application with Redis broker
   - Configuration from settings (broker, backend, serialization)
   - Auto-discovery of tasks from app.tasks
   - Signal handlers for task lifecycle (prerun, postrun, failure)
   - Celery Beat schedule for periodic tasks
   - Global instance: get_celery_app()

2. ‚úÖ **PDF Tasks** (app/tasks/pdf_tasks.py) - 200+ lines
   - parse_pdf_task - Async PDF parsing with MinerU/fallback
   - extract_positions_task - Position extraction from PDF with Claude
   - Retry logic with exponential backoff
   - Task status utilities

3. ‚úÖ **Enrichment Tasks** (app/tasks/enrichment_tasks.py) - 170+ lines
   - enrich_position_task - Single position enrichment with KROS/RTS
   - enrich_batch_task - Parallel batch processing using Celery groups
   - Result aggregation and error handling

4. ‚úÖ **Audit Tasks** (app/tasks/audit_tasks.py) - 190+ lines
   - audit_position_task - Multi-role AI audit (SME, ARCH, ENG, SUP)
   - audit_project_task - Project-level audit orchestration
   - Classification logic (GREEN/AMBER/RED)
   - HITL detection

5. ‚úÖ **Maintenance Tasks** (app/tasks/maintenance.py) - 220+ lines
   - cleanup_old_results - Daily cleanup of old task results
   - update_kb_cache - 6-hour KB cache refresh
   - cleanup_old_projects - Weekly project archival
   - health_check - System health monitoring

6. ‚úÖ **TaskMonitor Service** (app/services/task_monitor.py) - 270+ lines
   - Bridge between Celery tasks and BackgroundJob model
   - Task status tracking and updates
   - Project-level job monitoring
   - Task cancellation support

**Configuration Added (config.py):**
```python
CELERY_BROKER_URL: str          # Redis broker (db=1)
CELERY_RESULT_BACKEND: str      # Redis result backend
CELERY_TASK_TRACK_STARTED: bool # Track task start
CELERY_TASK_TIME_LIMIT: int     # 30 min hard limit
CELERY_TASK_SOFT_TIME_LIMIT: int # 25 min soft limit
CELERY_ACCEPT_CONTENT: list     # ["json"]
CELERY_TASK_SERIALIZER: str     # "json"
CELERY_RESULT_SERIALIZER: str   # "json"
```

**Celery Beat Schedule:**
- cleanup-old-results: Daily (24h) - Remove old task results
- update-kb-cache: Every 6 hours - Refresh KB cache

**Test Suite (tests/test_celery_integration.py):**
- 30+ tests covering all Celery operations
- Configuration tests (broker, serialization, time limits)
- Task registration tests (PDF, enrichment, audit, maintenance)
- TaskMonitor tests (status, cancellation)
- Integration tests (require Redis, currently skipped)

### üîó Monolit-Planner Integration (Nov 16-18) ‚úÖ LIVE

**Status:** ‚úÖ **INTEGRATION LIVE** (Smart Fallback Parser - Nov 18)

**Phase 1: Documentation & Planning (Nov 16)** ‚úÖ Complete
- INTEGRATION_CHECKLIST.md - 6-phase integration plan
- DOCKER_SETUP.md - Dockerfile & docker-compose
- KB_TRAINING_GUIDE.md - Knowledge base training
- API Adapter (550+ lines) - FastAPI endpoints
- TypeScript Client - Client library

**Phase 2: Implementation (Nov 18)** ‚úÖ Complete
- ‚úÖ Created POST `/api/parse-excel` endpoint (concrete-agent)
  - Accepts Excel files
  - Uses SmartParser (20+ column variants, EU numbers, header detection)
  - Returns positions + diagnostics
  - Commit: 15e9f2a

- ‚úÖ Created CORE API Client (Monolit-Planner)
  - `backend/src/services/coreAPI.js` (180+ lines)
  - parseExcelByCORE() - HTTP integration
  - convertCOREToMonolitPosition() - Format conversion
  - isCOREAvailable() - Health check

- ‚úÖ Integrated Fallback Chain (Monolit-Planner)
  - upload.js updated with 3-tier fallback
  - Local extractor (fast) ‚Üí CORE parser (smart) ‚Üí Templates (safety)
  - Tracks source in database (excel/core/templates)
  - Commit: 60a48ed

- ‚úÖ Created CORE_INTEGRATION.md documentation
  - Setup guide with env variables
  - Testing procedures
  - Troubleshooting & FAQ
  - Performance targets

**Smart Parser Capabilities:**
- ‚úÖ 20+ column name variants per field
- ‚úÖ Header detection in first 100 rows
- ‚úÖ EU number format parsing (1.234,56 ‚Üí 1234.56)
- ‚úÖ Service row filtering (Souhrn, Celkem, separators)
- ‚úÖ Full parsing diagnostics
- ‚úÖ 30-second timeout with fallback

**Environment Variables:**
```env
ENABLE_CORE_FALLBACK=true           # Enable/disable
CORE_API_URL=http://localhost:8000  # CORE endpoint
CORE_TIMEOUT=30000                  # 30s timeout
```

**Integration Timeline:**
- ‚úÖ Nov 16: Documentation (INTEGRATION_CHECKLIST, DOCKER_SETUP, KB guide)
- ‚úÖ Nov 18: Live implementation (endpoint, client, fallback)
- ‚è≥ Nov 19-23: Week 2 deployment (PostgreSQL, Redis, Celery on Render)
- ‚è≥ After Nov 23: Monorepo refactoring + complete integration

**Expected Results (Post-Deployment):**
- ‚úÖ 90%+ enrichment accuracy
- ‚úÖ <500ms parsing + conversion (CORE fallback)
- ‚úÖ 10+ positions/second throughput (with Celery)
- ‚úÖ <1% hallucination rate
- ‚úÖ Zero false positives

---

### üìä Recent Major Achievements
- ‚úÖ Phase 3 Week 6: Knowledge Base UI (Nov 5)
- ‚úÖ Competitive analysis Part 2 (Nov 6)
- ‚úÖ Development planning framework (Nov 6)
- ‚úÖ Phase 4 tech specs (4 files, 39k lines) (Nov 6)
- ‚úÖ Database schema migration created (Nov 7)
- ‚úÖ SQLAlchemy ORM models created (Nov 7)
- ‚úÖ Redis integration complete (Nov 7) - 3 modules, 1450+ lines
- ‚úÖ Celery queue system complete (Nov 9) - 6 modules, 1470+ lines
- ‚úÖ Monolit-Planner integration docs (Nov 16) - 4 documents, 3500+ lines
- ‚úÖ CORE-Monolit live integration (Nov 18) - Smart fallback parser operational
  - POST /api/parse-excel endpoint (concrete-agent)
  - CORE API client (Monolit-Planner)
  - 3-tier fallback chain (local ‚Üí CORE ‚Üí templates)
  - CORE_INTEGRATION.md documentation
  - 2 commits: 15e9f2a (CORE), 60a48ed (Monolit)

---

## Table of Contents

1. [Project Overview](#project-overview)
2. [Quick Start](#quick-start)
3. [Architecture Overview](#architecture-overview)
4. [Development Commands](#development-commands)
5. [Documentation Structure](#documentation-structure)
6. [Coding Standards](#coding-standards)
7. [Git Workflow](#git-workflow)
8. [Modular Changes](#modular-changes)
9. [Testing Strategy](#testing-strategy)
10. [Common Tasks](#common-tasks)
11. [Debugging](#debugging)

---

## Project Overview

**Concrete Agent** is a Czech/Slovak construction cost estimation and audit system powered by AI (Claude and GPT-4 Vision). The system processes construction estimates (V√Ωkaz v√Ωmƒõr/Rozpoƒçet), performs automated audits against KROS/RTS databases, and generates engineering deliverables.

### Key Features

- **Workflow A**: Import existing estimates ‚Üí Parse ‚Üí Validate ‚Üí Enrich ‚Üí Audit ‚Üí Export
- **Workflow B**: Upload drawings ‚Üí Extract specs ‚Üí Calculate quantities ‚Üí Generate positions ‚Üí Audit
- **Multi-role AI audit**: SME, ARCH, ENG, SUP expert consensus
- **Knowledge base**: KROS, RTS, ƒåSN standards, company rules
- **Deliverables**: Tech cards, resource schedules, Excel reports

### Technology Stack

| Component | Technology |
|-----------|-----------|
| **Backend** | FastAPI (Python 3.10+) |
| **Database** | PostgreSQL 16 (async with SQLAlchemy 2.0 + asyncpg) |
| **Cache** | Redis 5.0.1 with hiredis (sessions, caching, Pub/Sub) ‚úÖ |
| **Queue** | Celery 5.4.0 + Redis (background jobs, task scheduling) ‚úÖ |
| **AI** | Claude (Anthropic), GPT-4 Vision (OpenAI) |
| **Knowledge Base** | KROS, RTS, ƒåSN standards (JSON files) |
| **Migrations** | Alembic (async migrations) |
| **Testing** | pytest, pytest-asyncio |
| **API Docs** | OpenAPI (Swagger) |

---

## Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

**Key Dependencies (Phase 4 Backend Infrastructure):**
- **Database:** SQLAlchemy 2.0.36, asyncpg, psycopg2-binary
- **Migrations:** Alembic 1.13.1
- **Cache:** redis[hiredis]==5.0.1 (Redis with C parser)
- **Queue:** celery[redis]==5.4.0 (Task queue with Redis broker) ‚úÖ
- **Testing:** pytest, pytest-asyncio

**Full dependency list:** See `requirements.txt`

### 2. Configure Environment

Create `.env` file:

```env
# ==========================================
# AI API Keys
# ==========================================
# Required for Workflow A
ANTHROPIC_API_KEY=sk-ant-...

# Required for Workflow B
OPENAI_API_KEY=sk-...

# Optional - for live knowledge base
PERPLEXITY_API_KEY=pplx-...

# ==========================================
# Database & Cache (Phase 4)
# ==========================================
# PostgreSQL async connection
DATABASE_URL=postgresql+asyncpg://user:password@localhost/concrete_agent_dev

# Redis for sessions and caching
REDIS_URL=redis://localhost:6379/0

# Session TTL (default: 3600 = 1 hour)
SESSION_TTL=3600

# Cache TTL (default: 300 = 5 minutes)
CACHE_TTL=300

# ==========================================
# Application Settings
# ==========================================
ENVIRONMENT=development
LOG_LEVEL=INFO
```

### 3. Run Application

```bash
# Development (hot reload)
python -m uvicorn app.main:app --reload

# Production
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

### 4. Access API Docs

- Interactive: http://localhost:8000/docs
- Alternative: http://localhost:8000/redoc
- Health check: http://localhost:8000/health

---

## Architecture Overview

### Two Main Workflows

**Workflow A (Import & Audit):**

```
Upload ‚Üí Parse ‚Üí Validate ‚Üí Enrich ‚Üí Audit ‚Üí Export
  ‚Üì        ‚Üì        ‚Üì          ‚Üì        ‚Üì        ‚Üì
 XML/    Smart   Pydantic   KROS    Multi-   Excel
Excel   Parser   Schema    Match    Role     Report
```

**Reference:** [WORKFLOWS.md](docs/WORKFLOWS.md)

**Workflow B (Generate from Drawings):**

```
Upload ‚Üí Analyze ‚Üí Calculate ‚Üí Generate ‚Üí Audit ‚Üí Export
  ‚Üì         ‚Üì          ‚Üì           ‚Üì        ‚Üì        ‚Üì
 PDF     GPT-4    Concrete/   Claude   Multi-   Excel
Drawing  Vision   Rebar Qty   KROS     Role    Report
```

**Reference:** [WORKFLOWS.md](docs/WORKFLOWS.md)

### Core Architecture Layers

**5-Layer Architecture:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. API Layer (FastAPI)                  ‚îÇ ‚Üê routes.py, routes_workflow_a.py
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 2. Service Layer                        ‚îÇ ‚Üê workflow_a.py, audit_service.py
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 3. Parser Layer                         ‚îÇ ‚Üê kros_parser.py, excel_parser.py
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 4. AI Layer                             ‚îÇ ‚Üê claude_client.py, gpt4_client.py
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 5. Data Layer (KB + Models)             ‚îÇ ‚Üê knowledge_base/, models/
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Reference:** [ARCHITECTURE.md](ARCHITECTURE.md)

**Key directories:**

```
app/
‚îú‚îÄ‚îÄ api/                    # Layer 1: API routes
‚îÇ   ‚îú‚îÄ‚îÄ routes.py           # Main API routes
‚îÇ   ‚îú‚îÄ‚îÄ routes_workflow_a.py # Workflow A endpoints
‚îÇ   ‚îú‚îÄ‚îÄ routes_workflow_b.py # Workflow B endpoints
‚îÇ   ‚îî‚îÄ‚îÄ routes_agents.py    # Agent management endpoints
‚îú‚îÄ‚îÄ services/               # Layer 2: Business logic
‚îÇ   ‚îú‚îÄ‚îÄ workflow_a.py       # Workflow A service
‚îÇ   ‚îú‚îÄ‚îÄ audit_service.py    # Multi-role audit
‚îÇ   ‚îî‚îÄ‚îÄ enricher.py         # Position enrichment
‚îú‚îÄ‚îÄ parsers/                # Layer 3: Document parsing
‚îÇ   ‚îú‚îÄ‚îÄ kros_parser.py      # KROS XML parser
‚îÇ   ‚îú‚îÄ‚îÄ excel_parser.py     # Excel parser
‚îÇ   ‚îî‚îÄ‚îÄ pdf_parser.py       # PDF extraction
‚îú‚îÄ‚îÄ core/                   # Layer 4: Core infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ claude_client.py    # Claude API client
‚îÇ   ‚îú‚îÄ‚îÄ gpt4_client.py      # GPT-4 API client
‚îÇ   ‚îú‚îÄ‚îÄ perplexity_client.py # Perplexity API client
‚îÇ   ‚îú‚îÄ‚îÄ config.py           # Configuration & settings
‚îÇ   ‚îú‚îÄ‚îÄ redis_client.py     # Redis async client (Phase 4) ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ session.py          # Session management (Phase 4) ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ cache.py            # Caching layer (Phase 4) ‚úÖ
‚îú‚îÄ‚îÄ db/                     # Database layer (Phase 4) ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ models/             # SQLAlchemy ORM models
‚îÇ       ‚îú‚îÄ‚îÄ base.py         # Base model with UUID & timestamps
‚îÇ       ‚îú‚îÄ‚îÄ user.py         # User authentication
‚îÇ       ‚îú‚îÄ‚îÄ project.py      # Project tracking
‚îÇ       ‚îú‚îÄ‚îÄ document.py     # File uploads
‚îÇ       ‚îú‚îÄ‚îÄ position.py     # Budget line items
‚îÇ       ‚îú‚îÄ‚îÄ audit.py        # Audit results
‚îÇ       ‚îú‚îÄ‚îÄ chat.py         # Chat messages
‚îÇ       ‚îú‚îÄ‚îÄ job.py          # Background jobs
‚îÇ       ‚îú‚îÄ‚îÄ version.py      # Version control
‚îÇ       ‚îú‚îÄ‚îÄ kb_cache.py     # KB cache
‚îÇ       ‚îî‚îÄ‚îÄ credential.py   # Encrypted credentials
‚îú‚îÄ‚îÄ models/                 # Layer 5: Pydantic schemas
‚îú‚îÄ‚îÄ knowledge_base/         # Layer 5: KB (B1-B9)
‚îÇ   ‚îú‚îÄ‚îÄ B1_urs_codes/       # Construction codes
‚îÇ   ‚îú‚îÄ‚îÄ B2_csn_standards/   # Czech standards
‚îÇ   ‚îú‚îÄ‚îÄ B3_current_prices/  # Market prices
‚îÇ   ‚îú‚îÄ‚îÄ B5_tech_cards/      # Technical specs
‚îÇ   ‚îî‚îÄ‚îÄ B9_Equipment_Specs/ # Equipment
‚îî‚îÄ‚îÄ utils/                  # Shared utilities

alembic/                    # Database migrations (Phase 4) ‚úÖ
‚îú‚îÄ‚îÄ versions/               # Migration files
‚îÇ   ‚îî‚îÄ‚îÄ 868b39220cfa_initial_schema.py # Initial 10-table schema
‚îî‚îÄ‚îÄ env.py                  # Async migration config

tests/                      # Test suite
‚îú‚îÄ‚îÄ test_imports.py         # Import validation (6 tests)
‚îú‚îÄ‚îÄ test_workflow_a_*.py    # Workflow A tests (18 tests)
‚îú‚îÄ‚îÄ test_*_parser.py        # Parser tests (12 tests)
‚îú‚îÄ‚îÄ test_*_enricher.py      # Service tests (15 tests)
‚îú‚îÄ‚îÄ test_file_security.py   # Security tests (13 tests)
‚îú‚îÄ‚îÄ test_redis_integration.py # Redis tests (20+ tests) ‚úÖ
‚îî‚îÄ‚îÄ ...                     # Total: 87+ tests

docs/                       # Complete documentation
‚îú‚îÄ‚îÄ TECH_SPECS/             # Phase 4 technical specs (4 files)
‚îú‚îÄ‚îÄ API.md                  # API documentation (27+ endpoints)
‚îú‚îÄ‚îÄ WORKFLOWS.md            # Workflow documentation
‚îú‚îÄ‚îÄ SYSTEM_DESIGN.md        # System design
‚îî‚îÄ‚îÄ TESTS.md                # Testing guide

data/                       # Project files (gitignored)
‚îî‚îÄ‚îÄ projects/               # Project-specific data
    ‚îî‚îÄ‚îÄ {project_id}/       # Individual project folders
```

### Architectural Patterns

**1. Fallback Chain Pattern:**

```python
Primary Parser ‚Üí Fallback Parser ‚Üí AI Extraction ‚Üí Diagnostics
```

All parsers implement multi-tier fallback for robustness.

**Reference:** [ARCHITECTURE.md](ARCHITECTURE.md#fallback-chain-pattern)

**2. Cache-Aside Pattern:**

```python
Check cache ‚Üí If miss, generate ‚Üí Store in cache ‚Üí Return
```

Project state cached in `data/projects/{project_id}/`.

**Reference:** [ARCHITECTURE.md](ARCHITECTURE.md#cache-aside-pattern)

**3. Multi-Role Validation:**

```python
Position ‚Üí [SME, ARCH, ENG, SUP] ‚Üí Consensus ‚Üí GREEN/AMBER/RED
```

**Reference:** [SYSTEM_DESIGN.md](docs/SYSTEM_DESIGN.md#multi-role-expert-system)

**4. Rate Limiting (Token Bucket):**

All AI API calls go through `rate_limiter.py`:
- Claude: 25k tokens/min
- GPT-4: 8k tokens/min

**Reference:** [ARCHITECTURE.md](ARCHITECTURE.md#rate-limiting-pattern)

---

## Development Commands

### Running the Application

```bash
# Development (hot reload)
python -m uvicorn app.main:app --reload

# Production
uvicorn app.main:app --host 0.0.0.0 --port 8000

# Direct entry point
python app/main.py

# Custom port
uvicorn app.main:app --port 8001
```

### Testing

```bash
# Run all tests (67 tests, ~17 seconds)
pytest

# Run with verbose output
pytest -v

# Run specific test file
pytest tests/test_imports.py

# Run specific test
pytest tests/test_imports.py::test_config_import

# Run by pattern
pytest -k "workflow_a"

# Run with coverage (requires pytest-cov)
pip install pytest-cov
pytest --cov=app --cov-report=html

# Exclude failing tests
pytest --ignore=tests/test_workflow_a_artifacts.py

# Stop on first failure
pytest -x

# Show print statements
pytest -s
```

**Reference:** [TESTS.md](docs/TESTS.md)

### Database Migrations (Phase 4)

```bash
# Create new migration
alembic revision --autogenerate -m "description"

# Apply migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1

# Show current migration
alembic current

# Show migration history
alembic history

# Generate SQL for migration (dry run)
alembic upgrade head --sql

# Reset database to specific revision
alembic downgrade <revision_id>
```

**Note:** Migrations require PostgreSQL running. See `alembic/versions/` for migration files.

### Redis Operations (Phase 4)

```bash
# Start Redis server (local)
redis-server

# Connect to Redis CLI
redis-cli

# Check Redis connection
redis-cli ping
# Expected output: PONG

# Monitor Redis commands
redis-cli monitor

# Get all keys with prefix
redis-cli KEYS "concrete:*"

# Flush all data (DANGER: deletes all data!)
redis-cli FLUSHALL
```

**Python usage:**
```python
from app.core.redis_client import get_redis
from app.core.session import get_session_manager
from app.core.cache import get_kb_cache

# Redis client
redis = await get_redis()
await redis.set("key", {"data": "value"}, ttl=60)
value = await redis.get("key")

# Session management
session_mgr = await get_session_manager()
session_id = await session_mgr.create_session(user_id="user-123")

# Knowledge base cache
kb_cache = await get_kb_cache()
await kb_cache.cache_kros_lookup("121151113", kros_data)
```

### Git Commands

```bash
# Check status
git status

# Stage files
git add <file>

# Commit with conventional format
git commit -m "feat: add new parser for XC4 format"

# Push to remote
git push origin master

# View commit history
git log --oneline -10
```

**Reference:** [Git Workflow](#git-workflow)

### Linting & Formatting

```bash
# (Not configured - add if needed)
# flake8 app/
# black app/
# mypy app/
```

---

## Documentation Structure

### Primary Documentation Files

All documentation is comprehensive and cross-referenced:

| File | Purpose | Lines | Last Updated |
|------|---------|-------|--------------|
| **[README.md](README.md)** | Project overview, quickstart | 450+ | 2025-01-26 |
| **[ARCHITECTURE.md](ARCHITECTURE.md)** | 5-layer architecture, patterns | 800+ | 2025-01-26 |
| **[docs/SYSTEM_DESIGN.md](docs/SYSTEM_DESIGN.md)** | Technical specification | 1200+ | 2025-01-26 |
| **[docs/CONFIG.md](docs/CONFIG.md)** | Configuration reference | 600+ | 2025-01-26 |
| **[docs/API.md](docs/API.md)** | All 27+ API endpoints | 2230 | 2025-01-26 |
| **[docs/WORKFLOWS.md](docs/WORKFLOWS.md)** | Step-by-step workflows | 1351 | 2025-01-26 |
| **[docs/TESTS.md](docs/TESTS.md)** | Testing guide | 1706 | 2025-01-26 |
| **[docs/CONTRIBUTING.md](docs/CONTRIBUTING.md)** | Contributor guidelines | - | 2025-01-26 |
| **[CLAUDE.md](CLAUDE.md)** | Claude Code guidelines | This file | 2025-01-26 |

### When to Update Documentation

**IMPORTANT:** Always update relevant documentation when making changes:

| Change Type | Update These Docs |
|-------------|-------------------|
| New API endpoint | API.md |
| New workflow step | WORKFLOWS.md |
| New test | TESTS.md |
| New config option | CONFIG.md |
| New architecture pattern | ARCHITECTURE.md |
| New feature | README.md + SYSTEM_DESIGN.md |

### Documentation Cross-References

Always add cross-references between related docs:

```markdown
**Reference:** [WORKFLOWS.md](docs/WORKFLOWS.md#workflow-a-step-4)
**See also:** [API.md](docs/API.md#post-apiworkflowaenrich)
```

---

## Coding Standards

### Python Style

**1. Type Hints (Required):**

```python
# ‚úÖ Good
def enrich_position(position: dict, kb_loader: KBLoader) -> dict:
    enriched: dict = position.copy()
    return enriched

# ‚ùå Bad
def enrich_position(position, kb_loader):
    enriched = position.copy()
    return enriched
```

**2. Async/Await (Required for I/O):**

```python
# ‚úÖ Good
@router.post("/api/workflow/a/{project_id}/audit")
async def audit_project(project_id: str) -> dict:
    result = await workflow_a.run(project_id, action="audit")
    return result

# ‚ùå Bad (blocking I/O)
@router.post("/api/workflow/a/{project_id}/audit")
def audit_project(project_id: str) -> dict:
    result = workflow_a.run_sync(project_id, action="audit")  # Blocks event loop!
    return result
```

**3. Pydantic Models (Required for Data):**

```python
# ‚úÖ Good
from pydantic import BaseModel, Field

class Position(BaseModel):
    code: str = Field(..., description="KROS code")
    description: str
    quantity: float = Field(gt=0)
    unit: str

# ‚ùå Bad (untyped dicts)
position = {
    "code": "121151113",
    "description": "Beton C30/37",
    "quantity": 10.5,
    "unit": "m3"
}
```

**4. Error Handling (Specific Exceptions):**

```python
# ‚úÖ Good
try:
    result = parser.parse(file_path)
except FileNotFoundError:
    logger.error(f"File not found: {file_path}")
    raise HTTPException(status_code=404, detail="File not found")
except ValueError as e:
    logger.error(f"Invalid file format: {e}")
    raise HTTPException(status_code=400, detail="Invalid format")

# ‚ùå Bad (bare except)
try:
    result = parser.parse(file_path)
except:  # Too broad!
    raise HTTPException(status_code=500, detail="Error")
```

**5. Naming Conventions:**

```python
# Domain terms in Czech, tech terms in English
class VykazVymerParser:  # Czech: "bill of quantities"
    def parse(self, file_path: Path) -> dict:  # English: technical
        pozice = self._extract_positions()  # Czech: "positions"
        return {"positions": pozice}  # Mixed
```

**6. Comments (Czech for Domain Logic):**

```python
def classify_position(position: dict) -> str:
    # Klasifikace podle normy ƒåSN 73 1201
    if position["beton_trida"] >= "C30/37":
        return "GREEN"  # Vysok√° kvalita betonu
    return "AMBER"  # Vy≈æaduje kontrolu
```

### File Structure Standards

**1. Import Order:**

```python
# 1. Standard library
import json
from pathlib import Path
from typing import Optional, List

# 2. Third-party
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

# 3. Local (absolute imports)
from app.core.config import settings
from app.services.workflow_a import workflow_a
from app.models.position import Position
```

**2. Module Docstrings:**

```python
"""
Module for KROS UNIXML parsing with fallback strategies.

This parser handles Czech construction estimates in KROS format.
Implements multi-tier fallback: UNIXML ‚Üí Table XML ‚Üí Claude AI.

Reference: docs/SYSTEM_DESIGN.md#kros-parsing
"""
```

**3. Function Docstrings:**

```python
def enrich_position(position: dict, kb_loader: KBLoader) -> dict:
    """
    Enrich position with KROS/RTS database information.

    Args:
        position: Position dict with code, description, unit, quantity
        kb_loader: Knowledge base loader instance

    Returns:
        Enriched position dict with match, score, evidence

    Raises:
        ValueError: If position missing required fields

    Reference: docs/WORKFLOWS.md#workflow-a-step-4
    """
    ...
```

---

## Git Workflow

### Conventional Commits

**Format:** `<type>(<scope>): <subject>`

**Types:**

| Type | Usage | Example |
|------|-------|---------|
| `feat` | New feature | `feat(parser): add XC4 format support` |
| `fix` | Bug fix | `fix(audit): correct price deviation logic` |
| `docs` | Documentation | `docs: update WORKFLOWS.md with diagrams` |
| `test` | Tests | `test: add E2E test for Workflow B` |
| `refactor` | Code refactor | `refactor(enricher): simplify matching logic` |
| `perf` | Performance | `perf(parser): optimize XML parsing` |
| `chore` | Maintenance | `chore: update dependencies` |

**Examples:**

```bash
# Good commit messages
git commit -m "feat(api): add endpoint for tech card generation"
git commit -m "fix(parser): handle European number format (1 200,50)"
git commit -m "docs: add business-critical test scenarios to TESTS.md"
git commit -m "test(security): add path traversal attack tests"

# Bad commit messages
git commit -m "updates"
git commit -m "fix bug"
git commit -m "WIP"
```

### Commit Body Format

For complex changes, use multi-line commits:

```bash
git commit -m "$(cat <<'EOF'
feat(audit): implement multi-role expert consensus

- Add SME, ARCH, ENG, SUP expert roles
- Implement consensus algorithm
- Add conflict resolution logic
- Update classification thresholds

BREAKING CHANGE: Audit API now requires role_config parameter

Reference: docs/SYSTEM_DESIGN.md#multi-role-expert-system

ü§ñ Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude <noreply@anthropic.com>
EOF
)"
```

### Branch Strategy

**Current:** Single `master` branch (simple project)

**For larger teams, consider:**

```
master (production)
  ‚îú‚îÄ‚îÄ develop (integration)
  ‚îÇ   ‚îú‚îÄ‚îÄ feature/workflow-b-improvements
  ‚îÇ   ‚îú‚îÄ‚îÄ feature/new-parser-xc5
  ‚îÇ   ‚îî‚îÄ‚îÄ fix/audit-classification-bug
  ‚îî‚îÄ‚îÄ hotfix/critical-security-patch
```

---

## Modular Changes

### Principle: Small, Focused Changes

**‚úÖ Good:** One logical change per commit

```bash
# Commit 1: Add parser
git add app/parsers/xc5_parser.py
git commit -m "feat(parser): add XC5 format parser"

# Commit 2: Add tests
git add tests/test_xc5_parser.py
git commit -m "test(parser): add XC5 parser unit tests"

# Commit 3: Update docs
git add docs/SYSTEM_DESIGN.md
git commit -m "docs: add XC5 parser to SYSTEM_DESIGN.md"
```

**‚ùå Bad:** Multiple unrelated changes

```bash
# DON'T DO THIS
git add app/parsers/xc5_parser.py \
        app/services/workflow_a.py \
        tests/test_xc5_parser.py \
        docs/API.md \
        docs/WORKFLOWS.md
git commit -m "updates"
```

### When to Combine Changes

**Acceptable to combine when tightly coupled:**

```bash
# OK: Interface change requires updating implementation
git add app/models/position.py app/services/enricher.py
git commit -m "refactor(models): change Position.enrichment to nested dict"
```

### File-Level Changes

**1. New File:** Full implementation in one commit

```bash
git add app/parsers/new_parser.py
git commit -m "feat(parser): add NewParser with fallback chain"
```

**2. Modify Existing:** Focused changes only

```python
# ‚úÖ Good: Single responsibility change
def enrich_position(position: dict) -> dict:
    # Add new field
    position["confidence_score"] = calculate_confidence(position)
    return position

# ‚ùå Bad: Multiple unrelated changes
def enrich_position(position: dict) -> dict:
    # Add confidence score
    position["confidence_score"] = calculate_confidence(position)
    # Also refactor validation (should be separate commit!)
    position = validate_position(position)
    # Also add logging (should be separate commit!)
    logger.info(f"Enriched: {position['code']}")
    return position
```

### Testing Changes

**Always add tests for new code:**

```bash
# 1. Write code
git add app/services/new_feature.py
git commit -m "feat(service): add new feature"

# 2. Write tests
git add tests/test_new_feature.py
git commit -m "test(service): add tests for new feature"

# 3. Update docs
git add docs/SYSTEM_DESIGN.md
git commit -m "docs: document new feature in SYSTEM_DESIGN.md"
```

---

## Testing Strategy

### Test Categories (7 types)

| Category | Count | Purpose | Reference |
|----------|-------|---------|-----------|
| **Import** | 6 | CI/CD validation | tests/test_imports.py |
| **Integration** | 5 | Component interaction | tests/test_workflow_a_integration.py |
| **E2E** | 1 | Full pipeline | tests/test_workflow_a_e2e_numbers.py |
| **API** | 2 | REST endpoints | tests/test_workflow_a_artifacts.py |
| **Security** | 13 | Path traversal, etc. | tests/test_file_security.py |
| **Parser** | 12 | Document parsing | tests/test_*_parser.py |
| **Service** | 15 | Business logic | tests/test_*_enricher.py |

**Total:** 67 tests (65 passing, 2 failing, 97% pass rate)

**Reference:** [TESTS.md](docs/TESTS.md)

### Test Structure (AAA Pattern)

```python
def test_position_enrichment():
    # ARRANGE: Set up test data
    position = {"code": "121151113", "description": "Beton C30/37"}
    enricher = PositionEnricher(kb_loader=dummy_kb)

    # ACT: Execute operation
    result = enricher.enrich(position)

    # ASSERT: Verify outcome
    assert result["enrichment_status"] == "matched"
    assert result["unit_price"] > 0
    assert result["enrichment"]["match"] == "exact"
```

### Mock Patterns

**1. AsyncMock for Async Functions:**

```python
from unittest.mock import AsyncMock, patch

@pytest.mark.asyncio
async def test_workflow_execution():
    with patch.object(WorkflowA, 'execute', new_callable=AsyncMock) as mock:
        mock.return_value = {"success": True}
        result = await workflow_a.run(project_id="test-123")
    assert result["success"] is True
```

**2. TestClient for FastAPI:**

```python
from fastapi.testclient import TestClient
from app.main import app

def test_upload_endpoint():
    client = TestClient(app)
    response = client.post("/api/upload", files={"file": ...})
    assert response.status_code == 200
```

**3. tmp_path for Files:**

```python
def test_excel_export(tmp_path):
    output_file = tmp_path / "output.xlsx"
    exporter.export(data, output_file)
    assert output_file.exists()
    # Cleanup automatic
```

**Reference:** [TESTS.md](docs/TESTS.md#mock-structures)

### Business-Critical Tests

**‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Must always pass:**

1. **Complete Workflow A Pipeline** (test_workflow_a_e2e_numbers.py)
   - 53 positions ‚Üí Parse ‚Üí Validate ‚Üí Enrich ‚Üí Audit ‚Üí Export
   - European number format handling
   - GREEN/AMBER/RED classification

2. **Security: No Server Path Leakage** (test_file_security.py)
   - 13 tests covering upload, download, listing
   - Path traversal attack prevention

3. **KROS/OTSKP Position Enrichment** (test_position_enricher.py)
   - Exact/partial/no match strategies
   - Confidence scoring

**Reference:** [TESTS.md](docs/TESTS.md#business-critical-scenarios)

---

## Common Tasks

### 1. Adding a New API Endpoint

**Steps:**

1. Choose router file in `app/api/`
2. Add endpoint function
3. Update `app/api/__init__.py` if new router
4. Add tests in `tests/`
5. Update `docs/API.md`

**Example:**

```python
# app/api/routes_workflow_a.py
@router.post("/api/workflow/a/{project_id}/custom-action")
async def custom_action(project_id: str) -> dict:
    """
    Perform custom action on project.

    Reference: docs/WORKFLOWS.md#custom-action
    """
    result = await workflow_a.run(project_id, action="custom")
    return result
```

**Reference:** [API.md](docs/API.md)

### 2. Adding a New Parser

**Steps:**

1. Create `app/parsers/new_parser.py`
2. Implement `parse()` method
3. Add fallback chain
4. Add tests in `tests/test_new_parser.py`
5. Update `docs/SYSTEM_DESIGN.md`

**Template:**

```python
# app/parsers/new_parser.py
from pathlib import Path
from typing import Optional

class NewParser:
    """Parser for NEW format with fallback."""

    def parse(self, file_path: Path) -> dict:
        """
        Parse NEW format file.

        Returns:
            dict with positions, diagnostics

        Reference: docs/SYSTEM_DESIGN.md#new-parser
        """
        try:
            return self._primary_parse(file_path)
        except Exception as e:
            return self._fallback_parse(file_path)
```

### 3. Adding Knowledge Base Content

**Steps:**

1. Identify KB category: `app/knowledge_base/B{N}_category/`
2. Add JSON/Markdown files
3. Update `metadata.json`
4. KB auto-loads on startup

**Structure:**

```
app/knowledge_base/
‚îú‚îÄ‚îÄ B1_urs_codes/         # Construction codes
‚îú‚îÄ‚îÄ B2_csn_standards/     # Czech standards
‚îú‚îÄ‚îÄ B3_current_prices/    # Market prices
‚îú‚îÄ‚îÄ B5_tech_cards/        # Technical specs
‚îî‚îÄ‚îÄ B9_Equipment_Specs/   # Equipment
```

### 4. Modifying AI Prompts

**Location:** `app/prompts/`

**Special case - PDF prompt:**

1. Edit `docs/pdf_extraction_system_prompt_v2_1.md`
2. Run `scripts/sync_pdf_prompt.sh` to generate runtime module
3. Verify with `scripts/check_pdf_prompt.sh`
4. Commit both Markdown and Python files

**Reference:** [CONTRIBUTING.md](docs/CONTRIBUTING.md#pdf-prompt-workflow)

### 5. Working with Project State

**Use project cache API:**

```python
from app.services.project_cache import load_project_cache, save_project_cache

# Load project
project = load_project_cache(project_id)

# Modify
project["status"] = "analyzing"
project["progress"] = 0.5

# Save
save_project_cache(project_id, project)
```

**Or use utility paths:**

```python
from app.core.config import settings

audit_path = settings.DATA_DIR / "projects" / project_id / "audit_results.json"
```

---

## Debugging

### Enable Verbose Logging

**In `.env`:**

```env
LOG_LEVEL=DEBUG
LOG_CLAUDE_CALLS=true
LOG_GPT4_CALLS=true
```

**Log locations:**

```
logs/
‚îú‚îÄ‚îÄ claude_calls/      # Claude API interactions
‚îú‚îÄ‚îÄ gpt4_calls/        # GPT-4 API interactions
‚îî‚îÄ‚îÄ perplexity_calls/  # Perplexity API interactions
```

### Check Project State

**All project state in:**

```
data/projects/{project_id}/
‚îú‚îÄ‚îÄ project.json           # Main metadata
‚îú‚îÄ‚îÄ raw/                   # Uploaded files
‚îú‚îÄ‚îÄ processed/             # Parsed data
‚îî‚îÄ‚îÄ artifacts/             # Generated outputs
```

**Read to understand workflow state:**

```python
import json
from pathlib import Path

project_file = Path(f"data/projects/{project_id}/project.json")
project = json.loads(project_file.read_text())
print(f"Status: {project['status']}")
print(f"Progress: {project.get('progress', 0)}")
```

### Check API Rate Limits

```python
from app.core.rate_limiter import get_rate_limiter

limiter = get_rate_limiter()
stats = limiter.get_usage_stats()
print(f"Claude: {stats['claude']['tokens_used']}/{stats['claude']['tokens_limit']}")
print(f"GPT-4: {stats['gpt4']['tokens_used']}/{stats['gpt4']['tokens_limit']}")
```

### Test Parsers Independently

```python
from app.parsers.kros_parser import KROSParser
from app.core.claude_client import ClaudeClient

claude = ClaudeClient()
parser = KROSParser(claude_client=claude)
result = parser.parse(Path("test_files/sample.xml"))

print(f"Positions: {len(result['positions'])}")
print(f"Diagnostics: {result['diagnostics']}")
```

### Debug Tests

```bash
# Show print statements
pytest tests/test_imports.py -s

# Show full traceback
pytest tests/test_workflow_a_integration.py -v --tb=long

# Drop into debugger on failure
pytest tests/test_file_security.py --pdb

# Show local variables on failure
pytest tests/test_enricher.py -l
```

### Common Issues

**1. Import Errors**

```bash
# Add project root to PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
pytest
```

**2. 404 in API Tests**

Check route path matches:
- Test uses: `/api/workflow-a/workflow/a/{id}/tech-card`
- Actual route: `/api/workflow/a/{id}/tech-card` (likely)

**3. Async Test Warnings**

```python
# Missing decorator
@pytest.mark.asyncio  # Add this!
async def test_async_function():
    ...
```

**Reference:** [TESTS.md](docs/TESTS.md#troubleshooting)

---

## Important Notes

### Configuration

All configuration in `app/core/config.py` loaded from `.env`:

**Critical settings:**
- `ANTHROPIC_API_KEY` - Required for Workflow A
- `OPENAI_API_KEY` - Required for Workflow B
- `PERPLEXITY_API_KEY` - Optional for live KB search

**Feature flags:**
- `ENABLE_WORKFLOW_A` (default: true)
- `ENABLE_WORKFLOW_B` (default: false)
- `ENABLE_KROS_MATCHING` (default: true)
- `ENRICHMENT_ENABLED` (default: true)

**Reference:** [CONFIG.md](docs/CONFIG.md)

### Audit Classification Logic

```python
GREEN (‚â•95% confidence):
- High-quality match
- Proceed automatically

AMBER (75-95% confidence):
- Reasonable match
- May need review

RED (<75% confidence):
- Poor match
- Requires human review (HITL)
```

**Additional HITL triggers:**
- Price deviation >15% from norm
- Conflict between expert roles
- Missing critical fields

**Reference:** [SYSTEM_DESIGN.md](docs/SYSTEM_DESIGN.md#classification-logic)

### PDF Text Recovery

**Intelligent extraction pipeline:**

1. Try pdfplumber (primary)
2. Check valid character ratio (‚â•60%)
3. Detect PUA glyphs (encoding issues)
4. Fallback to Poppler/pdftotext
5. Queue for OCR if needed (max 5 pages)
6. Per-page timeouts prevent hanging

**Reference:** [SYSTEM_DESIGN.md](docs/SYSTEM_DESIGN.md#pdf-extraction)

### Multi-Role Expert System

**Four expert roles:**
- **SME** (Subject Matter Expert) - Domain knowledge
- **ARCH** (Architect) - Design compliance
- **ENG** (Engineer) - Technical feasibility
- **SUP** (Supervisor) - Construction practicality

**Consensus required before classification.**

**Reference:** [ARCHITECTURE.md](ARCHITECTURE.md#multi-role-validation-pattern)

---

## Starter Repository Recommendations

This project follows best practices from modern Python starter repositories:

### 1. Project Structure (FastAPI Best Practices)

```
‚úÖ Layered architecture (API ‚Üí Service ‚Üí Data)
‚úÖ Pydantic models for validation
‚úÖ Dependency injection patterns
‚úÖ Async/await throughout
‚úÖ OpenAPI documentation auto-generated
```

### 2. Testing (pytest Best Practices)

```
‚úÖ Comprehensive test coverage (97%)
‚úÖ Multiple test categories (unit, integration, E2E)
‚úÖ Mock patterns for external dependencies
‚úÖ Fixtures for reusable test data
‚úÖ Fast execution (~17 seconds for 67 tests)
```

### 3. Documentation (README Driven Development)

```
‚úÖ Comprehensive README with badges
‚úÖ Architecture documentation
‚úÖ API documentation (OpenAPI + custom)
‚úÖ Contributing guidelines
‚úÖ Workflow documentation
```

### 4. Configuration (12-Factor App)

```
‚úÖ Environment variables for config (.env)
‚úÖ Feature flags for toggles
‚úÖ Separate dev/staging/prod environments
‚úÖ No secrets in code
```

### 5. Git Workflow (Conventional Commits)

```
‚úÖ Conventional commit messages
‚úÖ Semantic versioning
‚úÖ Changelog generation ready
‚úÖ Small, focused commits
```

### 6. Code Quality

```
‚ö†Ô∏è Type hints (present, could be more complete)
‚ö†Ô∏è Linting (not configured - add flake8/black)
‚ö†Ô∏è Pre-commit hooks (not configured)
‚úÖ Error handling with specific exceptions
‚úÖ Logging throughout
```

**Recommendations for improvement:**

1. Add `pre-commit` hooks for linting
2. Add `black` for code formatting
3. Add `mypy` for type checking
4. Add `flake8` for linting
5. Add CI/CD pipeline (GitHub Actions)
6. Add changelog generation (conventional-changelog)

---

**Last updated:** 2025-11-16
**Version:** 2.2.0
**Maintained by:** Development Team
**Questions?** See [CONTRIBUTING.md](docs/CONTRIBUTING.md)

**Recent Updates (Nov 16):**
- ‚úÖ Added Monolit-Planner integration documentation
- ‚úÖ Created 4 integration guides (checklist, Docker, KB training, TypeScript client)
- ‚úÖ Added API adapter for seamless integration
- ‚úÖ Confirmed Redis and Celery in production
- ‚úÖ Ready for 3-5 day integration timeline
