# Batch URS Matcher - Architecture

**Version:** 1.0.0
**Date:** 2026-02-02
**Status:** Implementation In Progress

---

## Overview

Batch URS Matcher extends the existing manual mode (1 position â†’ candidates) with a **batch mode** that processes entire BOQ lists automatically. It detects composite positions (multiple works hidden in one line), splits them, and matches each subwork to ÃšRS codes.

**Core Principle:** LLM (interpret) â†’ Perplexity (retrieve) â†’ LLM (rerank)

---

## Key Requirements

### ðŸ”´ Critical Constraints

1. **No Breaking Changes** - Manual mode must continue working exactly as before
2. **No Hallucinations** - ÃšRS codes ONLY from search results, never invented
3. **Resume Support** - Batch jobs must be pausable and resumable
4. **Cache Everything** - Avoid duplicate API calls (cost optimization)
5. **Use Gemini** - Default LLM for cost optimization (40-250x cheaper than Claude)
6. **Comprehensive Logging** - Log every AI decision with reasoning + timing
7. **Subordinate Context** - Use CHILD rows as context, don't process them as separate positions

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         BATCH PROCESSOR                              â”‚
â”‚                                                                      â”‚
â”‚  Input: BOQ List (text/Excel/project)                               â”‚
â”‚      â”‚                                                               â”‚
â”‚      â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ 1. TEXT NORMALIZER                            â”‚                   â”‚
â”‚  â”‚    - Clean text (remove drawings, duplicates) â”‚                   â”‚
â”‚  â”‚    - Extract features (material, operation)   â”‚                   â”‚
â”‚  â”‚    - Normalize units                          â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚      â”‚                                                               â”‚
â”‚      â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ 2. WORK SPLITTER (LLM - Gemini)              â”‚                   â”‚
â”‚  â”‚    - Detect: SINGLE vs COMPOSITE              â”‚                   â”‚
â”‚  â”‚    - Split composite into SubWork[] (max 5)   â”‚                   â”‚
â”‚  â”‚    - Keywords: vÄetnÄ›, komplet, dodÃ¡vka a     â”‚                   â”‚
â”‚  â”‚      montÃ¡Å¾, demontÃ¡Å¾, vÃ½kop+odvoz+zÃ¡syp      â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚      â”‚                                                               â”‚
â”‚      â–¼                                                               â”‚
â”‚  FOR EACH SubWork:                                                   â”‚
â”‚      â”‚                                                               â”‚
â”‚      â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ 3. CANDIDATE RETRIEVER (Perplexity)          â”‚                   â”‚
â”‚  â”‚    - Generate 2-4 search queries              â”‚                   â”‚
â”‚  â”‚    - Search online ÃšRS catalog                â”‚                   â”‚
â”‚  â”‚    - Return 10-30 candidates                  â”‚                   â”‚
â”‚  â”‚    - Deduplicate results                      â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚      â”‚                                                               â”‚
â”‚      â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ 4. CANDIDATE RERANKER (LLM - Gemini)         â”‚                   â”‚
â”‚  â”‚    - Score each candidate (0-100)             â”‚                   â”‚
â”‚  â”‚    - Select top 3-4                           â”‚                   â”‚
â”‚  â”‚    - Add confidence (high/medium/low)         â”‚                   â”‚
â”‚  â”‚    - Add reasoning + evidence                 â”‚                   â”‚
â”‚  â”‚    - Flag needs_review if uncertain           â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚      â”‚                                                               â”‚
â”‚      â–¼                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ 5. BATCH CACHE                                â”‚                   â”‚
â”‚  â”‚    - Store results (avoid duplicate calls)    â”‚                   â”‚
â”‚  â”‚    - Enable resume from any point             â”‚                   â”‚
â”‚  â”‚    - Track status per position                â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚      â”‚                                                               â”‚
â”‚      â–¼                                                               â”‚
â”‚  Output:                                                             â”‚
â”‚  - Table (UI): LineNo | Text | SubWorks | Candidates | Scores       â”‚
â”‚  - Excel: Matches sheet + Summary sheet                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Model

### Database Schema (SQLite)

#### batch_jobs
```sql
CREATE TABLE batch_jobs (
  id TEXT PRIMARY KEY,
  name TEXT NOT NULL,
  status TEXT NOT NULL CHECK(status IN ('queued', 'running', 'paused', 'completed', 'failed')),
  settings TEXT NOT NULL,  -- JSON: {candidatesPerWork, maxSubWorks, searchDepth, language}
  total_items INTEGER DEFAULT 0,
  processed_items INTEGER DEFAULT 0,
  error_count INTEGER DEFAULT 0,
  needs_review_count INTEGER DEFAULT 0,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  started_at DATETIME,
  completed_at DATETIME,
  error_message TEXT
);
```

#### batch_items
```sql
CREATE TABLE batch_items (
  id TEXT PRIMARY KEY,
  batch_id TEXT NOT NULL REFERENCES batch_jobs(id) ON DELETE CASCADE,
  line_no INTEGER,
  original_text TEXT NOT NULL,
  normalized_text TEXT,
  detected_type TEXT CHECK(detected_type IN ('SINGLE', 'COMPOSITE', 'UNKNOWN')),
  status TEXT NOT NULL CHECK(status IN ('queued', 'parsed', 'split', 'retrieved', 'ranked', 'done', 'error', 'needs_review')),
  sub_works TEXT,  -- JSON: [{text, keywords, features}]
  results TEXT,    -- JSON: [{subWork, candidates: [{code, name, unit, score, confidence, reason, evidence}]}]
  error_message TEXT,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_batch_items_batch_id ON batch_items(batch_id);
CREATE INDEX idx_batch_items_status ON batch_items(status);
```

#### batch_cache
```sql
CREATE TABLE batch_cache (
  id TEXT PRIMARY KEY,
  cache_key TEXT NOT NULL UNIQUE,  -- Hash of (normalized_text + settings)
  stage TEXT NOT NULL CHECK(stage IN ('split', 'retrieve', 'rerank')),
  result TEXT NOT NULL,  -- JSON result
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  expires_at DATETIME
);

CREATE INDEX idx_batch_cache_key ON batch_cache(cache_key);
CREATE INDEX idx_batch_cache_expires ON batch_cache(expires_at);
```

---

## Service Modules

### 1. textNormalizer.js

**Purpose:** Clean and extract features from raw position text.

**Input:**
```javascript
{
  originalText: "VÃ½kop stavebnÃ­ jÃ¡my kat. 3, h=2.5m, vÄ. odvoz na sklÃ¡dku 10km (231112)",
  context: {
    parentText: "HSV - ZemnÃ­ prÃ¡ce",
    previousRows: ["DÃ­l 0 - VÅ¡eobecnÃ© konstrukce"]
  }
}
```

**Output:**
```javascript
{
  normalizedText: "VÃ½kop stavebnÃ­ jÃ¡my kat. 3, h=2.5m, vÄ. odvoz na sklÃ¡dku 10km",
  features: {
    operation: "vÃ½kop",
    object: "stavebnÃ­ jÃ¡ma",
    material: "kategorie 3",
    depth: "2.5m",
    additionalWork: "odvoz na sklÃ¡dku",
    distance: "10km"
  },
  markers: {
    hasComposite: true,  // "vÄ."
    hasTransport: true,
    hasDemolition: false
  }
}
```

**Algorithm:**
- Remove: drawing numbers, section codes, duplicate spaces
- Extract: numbers, units, materials, classes, thicknesses
- Detect: ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ‚Ð½Ñ‹Ðµ Ð¼Ð°Ñ€ÐºÐµÑ€Ñ‹ (vÄetnÄ›, komplet, dodÃ¡vka a montÃ¡Å¾)

---

### 2. workSplitter.js (LLM)

**Purpose:** Detect if position is SINGLE or COMPOSITE, split if needed.

**Input:**
```javascript
{
  normalizedText: "VÃ½kop jÃ¡my + odvoz + zÃ¡syp + hutnÄ›nÃ­",
  features: { ... },
  maxSubWorks: 5
}
```

**Output:**
```javascript
{
  detectedType: "COMPOSITE",
  subWorks: [
    {
      index: 1,
      text: "VÃ½kop jÃ¡my",
      operation: "excavation",
      keywords: ["vÃ½kop", "jÃ¡ma", "excavation"]
    },
    {
      index: 2,
      text: "Odvoz vÃ½kopku",
      operation: "transport",
      keywords: ["odvoz", "transport", "removal"]
    },
    {
      index: 3,
      text: "ZÃ¡syp jÃ¡my",
      operation: "backfill",
      keywords: ["zÃ¡syp", "backfill"]
    },
    {
      index: 4,
      text: "HutnÄ›nÃ­ zÃ¡sypu",
      operation: "compaction",
      keywords: ["hutnÄ›nÃ­", "compaction"]
    }
  ],
  reasoning: "Detected 4 distinct works separated by '+' marker",
  confidence: "high"
}
```

**LLM Prompt (Gemini 2.0 Flash):**
```
You are a construction BOQ expert. Analyze this position and determine if it contains multiple works.

INPUT:
Text: {normalizedText}
Features: {features}

RULES:
1. SINGLE = one work operation
2. COMPOSITE = 2-5 separate works (split them)
3. Markers: "vÄetnÄ›", "vÄ.", "+", "komplet", "dodÃ¡vka a montÃ¡Å¾", "se vÅ¡Ã­m"
4. Max 5 subworks - if more, mark as needs_review

OUTPUT (JSON):
{
  "detectedType": "SINGLE" | "COMPOSITE",
  "subWorks": [{index, text, operation, keywords}],
  "reasoning": "short explanation",
  "confidence": "high" | "medium" | "low"
}
```

---

### 3. candidateRetriever.js (Perplexity)

**Purpose:** Search online ÃšRS catalog for matching codes.

**Input:**
```javascript
{
  subWork: {
    text: "VÃ½kop jÃ¡my",
    operation: "excavation",
    keywords: ["vÃ½kop", "jÃ¡ma"]
  },
  searchDepth: "normal"  // quick=2, normal=3, deep=4 queries
}
```

**Output:**
```javascript
{
  subWork: { ... },
  candidates: [
    {
      code: "121101101",
      name: "HloubenÃ­ jam nezapaÅ¾enÃ½ch v horninÄ› tÅ™. 3",
      unit: "m3",
      snippet: "VÃ½kop stavebnÃ­ch jam a Å¡achet nezapaÅ¾enÃ½ch...",
      source: "https://katalogy.ckait.cz/urs/...",
      searchQuery: "vÃ½kop stavebnÃ­ jÃ¡ma kategorie 3"
    },
    // ... 10-30 candidates
  ],
  queriesUsed: ["vÃ½kop jÃ¡ma kategorie 3", "hloubenÃ­ jÃ¡ma nezapaÅ¾enÃ¡", "vÃ½kop hornina tÅ™Ã­da 3"],
  timing: {
    query1Ms: 1240,
    query2Ms: 1180,
    totalMs: 2420
  }
}
```

**Algorithm:**
1. Generate 2-4 queries based on searchDepth:
   - Strict: operation + material + key feature
   - Expanded: synonyms + variations
   - Reverse: object + operation
2. Call Perplexity for each query
3. Deduplicate candidates (by code)
4. Return top 30 max

---

### 4. candidateReranker.js (LLM)

**Purpose:** Score and select top candidates from retrieved list.

**Input:**
```javascript
{
  subWork: {
    text: "VÃ½kop jÃ¡my",
    operation: "excavation",
    keywords: ["vÃ½kop", "jÃ¡ma"]
  },
  candidates: [
    {code: "121101101", name: "HloubenÃ­ jam...", unit: "m3"},
    // ... 30 candidates
  ],
  topN: 4
}
```

**Output:**
```javascript
{
  subWork: { ... },
  topCandidates: [
    {
      rank: 1,
      code: "121101101",
      name: "HloubenÃ­ jam nezapaÅ¾enÃ½ch v horninÄ› tÅ™. 3",
      unit: "m3",
      score: 95,
      confidence: "high",
      reason: "Exact match for excavation + category 3 + pit",
      evidence: "stavebnÃ­ jÃ¡ma + kategorie 3 + hloubenÃ­",
      needsReview: false
    },
    {
      rank: 2,
      code: "121101201",
      name: "HloubenÃ­ jam zapaÅ¾enÃ½ch v horninÄ› tÅ™. 3",
      unit: "m3",
      score: 75,
      confidence: "medium",
      reason: "Similar but assumes shoring (zapaÅ¾enÃ­)",
      evidence: "jÃ¡ma + kategorie 3",
      needsReview: false
    },
    // ... up to 4 candidates
  ],
  reasoning: "Top candidate matches all key features",
  timing: {
    llmMs: 2340
  }
}
```

**LLM Prompt (Gemini 2.0 Flash):**
```
You are a ÃšRS expert. Score these candidates for the work description.

WORK:
Text: {subWork.text}
Operation: {subWork.operation}
Keywords: {subWork.keywords}

CANDIDATES (from search):
{candidates.map(c => `${c.code}: ${c.name} (${c.unit})`)}

RULES:
1. ONLY select from the candidates list (NO invented codes)
2. Score 0-100 based on: operation match, material match, unit match
3. Confidence: high (90+), medium (70-89), low (<70)
4. If no good match, return score=0 + confidence=low + needsReview=true
5. Return top {topN} candidates

OUTPUT (JSON):
{
  "topCandidates": [
    {
      "rank": 1,
      "code": "...",
      "name": "...",
      "unit": "...",
      "score": 0-100,
      "confidence": "high" | "medium" | "low",
      "reason": "1 sentence",
      "evidence": "key matching words",
      "needsReview": false
    }
  ],
  "reasoning": "overall assessment"
}
```

---

### 5. batchProcessor.js (Orchestrator)

**Purpose:** Main pipeline controller.

**Flow:**
```javascript
async function processPosition(batchId, itemId) {
  const item = await db.getBatchItem(itemId);
  const settings = await db.getBatchJob(batchId).settings;

  try {
    // Step 1: Normalize
    updateStatus(itemId, 'parsed');
    const normalized = await textNormalizer.normalize(item.original_text, item.context);
    await db.updateItem(itemId, { normalized_text: normalized.normalizedText });

    // Step 2: Split (with cache)
    updateStatus(itemId, 'split');
    const cacheKey = hash(normalized.normalizedText + settings);
    let splitResult = await batchCache.get(cacheKey, 'split');
    if (!splitResult) {
      splitResult = await workSplitter.split(normalized, settings.maxSubWorks);
      await batchCache.set(cacheKey, 'split', splitResult, TTL_30_DAYS);
    }
    await db.updateItem(itemId, { detected_type: splitResult.detectedType, sub_works: splitResult.subWorks });

    // Step 3: Retrieve candidates for each subwork
    updateStatus(itemId, 'retrieved');
    const results = [];
    for (const subWork of splitResult.subWorks) {
      const retrieveCacheKey = hash(subWork.text + settings.searchDepth);
      let candidates = await batchCache.get(retrieveCacheKey, 'retrieve');
      if (!candidates) {
        candidates = await candidateRetriever.retrieve(subWork, settings.searchDepth);
        await batchCache.set(retrieveCacheKey, 'retrieve', candidates, TTL_7_DAYS);
      }

      // Step 4: Rerank candidates
      const rerankCacheKey = hash(subWork.text + JSON.stringify(candidates) + settings.candidatesPerWork);
      let reranked = await batchCache.get(rerankCacheKey, 'rerank');
      if (!reranked) {
        reranked = await candidateReranker.rerank(subWork, candidates, settings.candidatesPerWork);
        await batchCache.set(rerankCacheKey, 'rerank', reranked, TTL_7_DAYS);
      }

      results.push({
        subWork: subWork,
        candidates: reranked.topCandidates
      });
    }

    // Final status
    const needsReview = results.some(r => r.candidates.some(c => c.needsReview || c.confidence === 'low'));
    updateStatus(itemId, needsReview ? 'needs_review' : 'done');
    await db.updateItem(itemId, { results: results });

  } catch (error) {
    updateStatus(itemId, 'error');
    await db.updateItem(itemId, { error_message: error.message });
    throw error;
  }
}

async function processBatch(batchId) {
  const job = await db.getBatchJob(batchId);
  await db.updateBatchJob(batchId, { status: 'running', started_at: new Date() });

  const items = await db.getBatchItems(batchId, { status: ['queued', 'error'] });
  const concurrency = 3;  // Process 3 positions in parallel

  try {
    await pMap(items, async (item) => {
      await processPosition(batchId, item.id);
      await db.incrementProcessedCount(batchId);
    }, { concurrency });

    await db.updateBatchJob(batchId, { status: 'completed', completed_at: new Date() });
  } catch (error) {
    await db.updateBatchJob(batchId, { status: 'failed', error_message: error.message });
    throw error;
  }
}
```

---

### 6. batchCache.js

**Purpose:** Cache results to avoid duplicate API calls.

**API:**
```javascript
async function get(cacheKey, stage) {
  const cached = await db.getBatchCache(cacheKey, stage);
  if (!cached || cached.expires_at < new Date()) {
    return null;
  }
  return JSON.parse(cached.result);
}

async function set(cacheKey, stage, result, ttlMs) {
  const expires_at = new Date(Date.now() + ttlMs);
  await db.upsertBatchCache({
    id: uuid(),
    cache_key: cacheKey,
    stage: stage,
    result: JSON.stringify(result),
    expires_at: expires_at
  });
}

function hash(input) {
  return crypto.createHash('sha256').update(input).digest('hex');
}
```

**TTL:**
- Split: 30 days (position text rarely changes)
- Retrieve: 7 days (ÃšRS catalog updates slowly)
- Rerank: 7 days (scoring is deterministic)

---

## API Endpoints

### POST /api/batch/create
Create new batch job.

**Request:**
```json
{
  "name": "Project BOQ - 2026-02-02",
  "items": [
    {"lineNo": 1, "text": "VÃ½kop jÃ¡my kat. 3", "context": {...}},
    {"lineNo": 2, "text": "Beton C25/30 vÄ. doprava", "context": {...}}
  ],
  "settings": {
    "candidatesPerWork": 4,
    "maxSubWorks": 5,
    "searchDepth": "normal",
    "language": "cs"
  }
}
```

**Response:**
```json
{
  "batchId": "batch_xyz",
  "status": "queued",
  "totalItems": 2
}
```

---

### POST /api/batch/:id/start
Start processing batch.

**Response:**
```json
{
  "batchId": "batch_xyz",
  "status": "running",
  "startedAt": "2026-02-02T10:00:00Z"
}
```

---

### POST /api/batch/:id/pause
Pause batch processing.

**Response:**
```json
{
  "batchId": "batch_xyz",
  "status": "paused",
  "processedItems": 15,
  "totalItems": 100
}
```

---

### POST /api/batch/:id/resume
Resume paused batch.

**Response:**
```json
{
  "batchId": "batch_xyz",
  "status": "running",
  "processedItems": 15,
  "remainingItems": 85
}
```

---

### GET /api/batch/:id/status
Get batch status and progress.

**Response:**
```json
{
  "batchId": "batch_xyz",
  "status": "running",
  "totalItems": 100,
  "processedItems": 45,
  "errorCount": 2,
  "needsReviewCount": 8,
  "progress": 45,
  "estimatedTimeRemaining": "5 minutes"
}
```

---

### GET /api/batch/:id/results
Get batch results.

**Response:**
```json
{
  "batchId": "batch_xyz",
  "status": "completed",
  "results": [
    {
      "lineNo": 1,
      "originalText": "VÃ½kop jÃ¡my kat. 3",
      "detectedType": "SINGLE",
      "subWorks": [
        {
          "index": 1,
          "text": "VÃ½kop jÃ¡my kat. 3",
          "candidates": [
            {
              "rank": 1,
              "code": "121101101",
              "name": "HloubenÃ­ jam...",
              "unit": "m3",
              "score": 95,
              "confidence": "high",
              "reason": "Exact match",
              "evidence": "vÃ½kop + jÃ¡ma + kategorie 3",
              "needsReview": false
            }
          ]
        }
      ]
    }
  ]
}
```

---

### GET /api/batch/:id/export/xlsx
Export results to Excel.

**Response:** Excel file (application/vnd.openxmlformats-officedocument.spreadsheetml.sheet)

**Sheet 1: Matches**
| LineNo | OriginalText | DetectedType | SubWorkNo | SubWorkText | CandidateRank | UrsCode | UrsName | UrsUnit | Score | Confidence | NeedsReview | Reason | Evidence | Source |
|--------|--------------|--------------|-----------|-------------|---------------|---------|---------|---------|-------|------------|-------------|--------|----------|--------|

**Sheet 2: Summary**
```
Total Positions: 100
SINGLE: 75
COMPOSITE: 25
  - 2 subworks: 15
  - 3 subworks: 8
  - 4 subworks: 2

Confidence:
  High: 85
  Medium: 12
  Low: 3

Needs Review: 8
Errors: 2
```

---

## Logging Strategy

### Log Levels

**INFO:** Progress updates
```
[Batch:batch_xyz] Started processing 100 items
[Batch:batch_xyz] Item 1/100: Parsed + Normalized
[Batch:batch_xyz] Item 1/100: Split â†’ COMPOSITE (3 subworks)
[Batch:batch_xyz] Completed: 45/100 (45%)
```

**DEBUG:** Detailed AI decisions
```
[WorkSplitter] Input: "VÃ½kop + odvoz + zÃ¡syp"
[WorkSplitter] LLM (Gemini-2.0-Flash): detectedType=COMPOSITE, subWorks=3, confidence=high
[WorkSplitter] Reasoning: "Detected 3 distinct operations separated by '+'"
[WorkSplitter] Timing: 1,240ms

[CandidateRetriever] SubWork: "VÃ½kop jÃ¡my"
[CandidateRetriever] Query 1: "vÃ½kop stavebnÃ­ jÃ¡ma kategorie 3"
[CandidateRetriever] Perplexity: 12 candidates found (1,180ms)
[CandidateRetriever] Query 2: "hloubenÃ­ jÃ¡ma nezapaÅ¾enÃ¡"
[CandidateRetriever] Perplexity: 8 candidates found (1,050ms)
[CandidateRetriever] Total candidates: 18 (deduplicated to 15)

[CandidateReranker] SubWork: "VÃ½kop jÃ¡my"
[CandidateReranker] Candidates: 15
[CandidateReranker] LLM (Gemini-2.0-Flash): Top 4 selected
[CandidateReranker] Rank 1: code=121101101, score=95, confidence=high
[CandidateReranker] Reasoning: "Exact match for excavation + category 3 + pit"
[CandidateReranker] Timing: 2,340ms
```

**WARN:** Low confidence / needs review
```
[CandidateReranker] WARNING: Low confidence (score=45) for "SpeciÃ¡lnÃ­ prÃ¡ce"
[CandidateReranker] Marked as needs_review=true
```

**ERROR:** Failures
```
[BatchProcessor] ERROR: Item batch_xyz_item_5 failed
[BatchProcessor] Error: Perplexity timeout after 60000ms
[BatchProcessor] Retrying in 2s...
```

---

## Frontend UI

### Batch Tab (new)

**Layout:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ URS MATCHER                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [ Manual Mode ]  [ Batch Mode ]  â† Tabs                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  BATCH MODE - Seznam pozic                                      â”‚
â”‚                                                                 â”‚
â”‚  Input Options:                                                 â”‚
â”‚  â—‹ Paste list (textarea)                                        â”‚
â”‚  â—‹ Select from project (dropdown)                               â”‚
â”‚                                                                 â”‚
â”‚  Settings:                                                      â”‚
â”‚  Candidates per work: [4 â–¼]                                     â”‚
â”‚  Max subworks: [5 â–¼]                                            â”‚
â”‚  Search depth: [â—‹ Quick â— Normal â—‹ Deep]                        â”‚
â”‚  Language: [Czech â–¼]                                            â”‚
â”‚                                                                 â”‚
â”‚  [ Start Batch ]  [ Pause ]  [ Resume ]  [ Export XLSX ]        â”‚
â”‚                                                                 â”‚
â”‚  Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 45/100 (45%)                    â”‚
â”‚  Needs Review: 8 | Errors: 2                                    â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ RESULTS TABLE                                            â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ â„–   â”‚ Original â”‚ Type â”‚ SubWork â”‚ Rank â”‚ ÃšRSâ”‚ Score   â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚ 1   â”‚ VÃ½kop... â”‚ SING â”‚ VÃ½kop...â”‚  1   â”‚ 12 â”‚ 95 âœ“    â”‚   â”‚
â”‚  â”‚     â”‚          â”‚      â”‚         â”‚  2   â”‚ 12 â”‚ 75 âœ“    â”‚   â”‚
â”‚  â”‚ 2   â”‚ Beton... â”‚ COMP â”‚ Beton...â”‚  1   â”‚ 24 â”‚ 90 âœ“    â”‚   â”‚
â”‚  â”‚     â”‚          â”‚      â”‚ Doprava â”‚  1   â”‚ 44 â”‚ 85 âœ“    â”‚   â”‚
â”‚  â”‚ 3   â”‚ Special..â”‚ SING â”‚ Special â”‚  1   â”‚ ?? â”‚ 45 âš     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚  Legend: âœ“ High conf. | â—‹ Medium | âš  Needs review             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Testing Plan

### Unit Tests

1. **textNormalizer**
   - Clean drawing numbers
   - Extract features (material, operation, depth)
   - Detect composite markers

2. **workSplitter**
   - SINGLE detection
   - COMPOSITE detection (vÄetnÄ›, +, komplet)
   - Max 5 subworks limit

3. **candidateRetriever**
   - Query generation
   - Deduplication
   - Timeout handling

4. **candidateReranker**
   - Score calculation
   - Confidence levels
   - No hallucinations (codes only from input)

5. **batchCache**
   - Cache hit/miss
   - TTL expiration
   - Hash collision

### Integration Tests

1. **SINGLE position** â†’ 1 subwork â†’ 3-4 candidates
2. **COMPOSITE position** â†’ 3 subworks â†’ 12 candidates total
3. **Resume after pause** â†’ continue from last position
4. **Rate limit** â†’ backoff + retry
5. **Empty search** â†’ unknown + confidence=low + needsReview=true

---

## Cost Optimization

### Model Selection (Gemini 2.0 Flash)

**Cost comparison (per 1M tokens):**
- Claude Sonnet 4.5: $3 input / $15 output
- GPT-4o: $5 input / $15 output
- **Gemini 2.0 Flash: $0.075 input / $0.30 output** â† 40-250x cheaper!

**Estimated costs (100 positions, 50% composite = 150 subworks):**
- Split: 150 LLM calls Ã— 500 tokens avg = 75k tokens â‰ˆ **$0.006**
- Rerank: 150 LLM calls Ã— 2k tokens avg = 300k tokens â‰ˆ **$0.113**
- Perplexity: 450 searches Ã— $0.005 = **$2.25**
- **Total: ~$2.37 per 100 positions**

With Claude: ~$60 per 100 positions (25x more expensive!)

### Caching Strategy

**Cache hit rates (estimated):**
- Split: 30% (common position patterns)
- Retrieve: 50% (same search queries)
- Rerank: 40% (same candidate lists)

**Savings:** ~40% cost reduction with cache

---

## Deployment Checklist

### Backend
- [ ] Database migrations (batch_jobs, batch_items, batch_cache)
- [ ] Environment variables (GOOGLE_API_KEY for Gemini)
- [ ] Service modules (6 files: normalizer, splitter, retriever, reranker, processor, cache)
- [ ] API routes (7 endpoints)
- [ ] Excel exporter
- [ ] Logging configuration

### Frontend
- [ ] Batch tab UI
- [ ] Input components (textarea, project selector)
- [ ] Settings panel
- [ ] Progress indicator
- [ ] Results table
- [ ] Export button

### Testing
- [ ] Unit tests (5 services)
- [ ] Integration tests (5 scenarios)
- [ ] Manual testing (SINGLE, COMPOSITE, Resume)

### Documentation
- [ ] API documentation
- [ ] User guide (how to use batch mode)
- [ ] Architecture doc (this file)

---

## Future Enhancements

1. **Smart grouping** - Group similar positions before processing
2. **Parallel Perplexity** - Search multiple subworks simultaneously
3. **User feedback loop** - Learn from corrections
4. **Cost dashboard** - Show real-time API costs
5. **Schedule processing** - Run batches overnight
6. **Multi-language** - Support RU/UA/EN positions

---

**Next Steps:** Begin implementation with database schema + textNormalizer service.

