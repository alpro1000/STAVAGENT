# URS Catalog Import Guide

**Version:** 1.0
**Last Updated:** 2025-12-10
**Status:** ‚úÖ Ready for use

---

## üéØ Purpose

Replace the **20 sample items** with a **complete official √öRS catalog** so that:
- ‚úÖ System works with real URS codes only
- ‚úÖ Searches are fast and accurate (offline)
- ‚úÖ Perplexity is only a helper, not the source of truth
- ‚úÖ No fake/made-up codes in results

---

## üì¶ What is √öRS?

**Jednotn√Ω Registr Stavebn√≠ch Dƒõl (JRSD/√öRS)**
- Official Czech construction catalog
- Contains ~40,000+ unique codes
- Organized by t≈ô√≠dn√≠k (classification sections)
- Maintained by ƒåKAIT (Czech Chamber of Architects and Engineers)

**Examples:**
- `274313821` - Z√°kladov√© pasy z betonu C30/37 (Foundation strips)
- `276313831` - Stƒõny z betonu C30/37 (≈ΩB walls)
- `311234567` - Zdivo z p√°len√Ωch cihel (Brickwork)
- `631311135` - Ochrann√° betonov√° mazanina (Protective concrete screed)

---

## üöÄ Quick Start (3 Steps)

### Step 1: Get √öRS Export File

**Option A: Use KROS/√öRS Official Website** (Recommended)
```
1. Visit https://www.urs.cz/ (Czech portal)
2. Login with your account (if required)
3. Export ‚Üí "Sta≈æen√≠ katalogu" or "Katalog stavebn√≠ch dƒõl"
4. Choose format: CSV, XLSX, or TSV
5. Save to: ./data/urs_export.csv
```

**Option B: Use Test CSV** (Development)
```bash
# Create minimal test file for testing import logic:
cat > data/urs_export.csv << 'EOF'
code,name,unit,section,description,category_path
274313811,Z√°kladov√© pasy z betonu C25/30,m3,27,Pasy z betonu,3 > 27 > Z√°klady
274313821,Z√°kladov√© pasy z betonu C30/37,m3,27,Pasy z betonu,3 > 27 > Z√°klady
276313831,Stƒõny z betonu C30/37,m3,27,≈ΩB stƒõny,3 > 27 > Betonov√© konstrukce
311234567,Zdivo z p√°len√Ωch cihel,m2,31,Ciheln√© zdivo,3 > 31 > Zdivo
631311135,Ochrann√° betonov√° mazanina C25/30,m3,63,Mazanina,6 > 63 > Podlahy
EOF
```

**Option C: Extract from Existing Project**
- Ask your team for their KROS/√öRS export
- Should be CSV/XLSX format
- Must have columns: code, name, unit

### Step 2: Run Import Script

```bash
cd /home/user/STAVAGENT/URS_MATCHER_SERVICE/backend

# Basic import (append to existing data)
node scripts/import_urs_catalog.mjs --from-csv ./data/urs_export.csv

# Import and replace old data (truncate first)
node scripts/import_urs_catalog.mjs --from-csv ./data/urs_export.csv --truncate
```

**Expected Output:**
```
[12:34:56] ‚úì Reading file: ./data/urs_export.csv
[12:34:56] ‚úì Parsed 5000 rows from CSV
[12:34:56] ‚úì Connecting to database: /home/user/STAVAGENT/URS_MATCHER_SERVICE/backend/data/urs_matcher.db
[12:34:56] ‚úì Progress: 25% (1250 imported, 0 skipped)
[12:34:57] ‚úì Progress: 50% (2500 imported, 0 skipped)
[12:34:58] ‚úì Progress: 75% (3750 imported, 0 skipped)
[12:34:59] ‚úì Progress: 100% (5000 imported, 0 skipped)

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚úì IMPORT COMPLETE
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Total rows processed: 5000
Successfully imported: 5000
Skipped/failed: 0
Total in database: 5000

Section breakdown:
  27: 1200 items
  31: 850 items
  32: 600 items
  41: 450 items
  43: 400 items
  ...
```

### Step 3: Verify Import

```bash
# Check database has data
cd /home/user/STAVAGENT/URS_MATCHER_SERVICE/backend
sqlite3 data/urs_matcher.db

# Query imported items
SELECT COUNT(*) FROM urs_items WHERE is_imported = 1;
SELECT * FROM urs_items LIMIT 10;
SELECT section_code, COUNT(*) FROM urs_items GROUP BY section_code;
```

---

## üìã Supported File Formats

### CSV (Recommended)
```
code,name,unit,section,description,category_path
```

Delimiter: Auto-detected (comma or tab)

### XLSX/XLS
Requires: `npm install xlsx`

### TSV (Tab-Separated)
Automatic delimiter detection

---

## üîÑ Column Mapping

The import script is **flexible with column names**:

| Target Field | Accepts | Example |
|--------------|---------|---------|
| **code** | code, k√≥d, urs_code, Code | 274313821 |
| **name** | name, n√°zev, urs_name, Description | Z√°kladov√© pasy |
| **unit** | unit, mj, measure_unit, Unit | m3 |
| **section** | section, t≈ô√≠dn√≠k, section_code | 27 |
| **description** | description, popis, desc | Pasy z betonu... |
| **category_path** | category_path, cesta, path | 3 > 27 > Z√°klady |

**If section is missing:** Auto-extracted from code (first 2-3 digits)

---

## üõ†Ô∏è Advanced Options

### Option 1: Truncate Before Import (Replace All)
```bash
node scripts/import_urs_catalog.mjs --from-csv ./data/urs_export.csv --truncate
```
- Removes all `is_imported = 1` items
- Keeps sample items (`is_imported = 0`)
- Then imports new data

### Option 2: Append (Keep Existing Data)
```bash
node scripts/import_urs_catalog.mjs --from-csv ./data/urs_export.csv
```
- Keeps existing items
- INSERT OR REPLACE (updates if code exists)
- Useful for incremental updates

### Option 3: Multiple Batches
```bash
# First import: larger file with section 27, 32, 41
node scripts/import_urs_catalog.mjs --from-csv ./data/part1.csv

# Second import: add more sections
node scripts/import_urs_catalog.mjs --from-csv ./data/part2.csv
```

---

## üîç Verify After Import

### Check Database Stats
```bash
sqlite3 data/urs_matcher.db << 'EOF'
SELECT 'Imported items' as type, COUNT(*) FROM urs_items WHERE is_imported = 1
UNION ALL
SELECT 'Sample items' as type, COUNT(*) FROM urs_items WHERE is_imported = 0
UNION ALL
SELECT 'By section 27' as type, COUNT(*) FROM urs_items WHERE section_code = '27'
UNION ALL
SELECT 'By section 31' as type, COUNT(*) FROM urs_items WHERE section_code = '31';
EOF
```

### Test Search (ursLocalMatcher)
```bash
# Start service
npm run dev

# In another terminal, test:
curl -X POST http://localhost:3001/api/jobs/text-match \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Z√°kladov√© pasy z betonu",
    "quantity": 10,
    "unit": "m3"
  }'

# Expected: Result from actual imported catalog (not sample items)
```

---

## üêõ Troubleshooting

### Issue 1: "Cannot find 'code' column"
```
Error: Cannot find 'code' column. Available columns: k√≥d, n√°zev, jednotka, ...
```

**Solution:**
Rename columns to match expected names, or modify the script's `fieldMap` section.

**Quick Fix:**
```bash
# Use sed to rename column
sed -i 's/k√≥d/code/g' data/urs_export.csv
sed -i 's/n√°zev/name/g' data/urs_export.csv
```

### Issue 2: "No records found"
```
Error: No records found in file
```

**Solution:**
1. Check file exists: `ls -la data/urs_export.csv`
2. Check file is not empty: `wc -l data/urs_export.csv`
3. Check first row (header): `head -1 data/urs_export.csv`

### Issue 3: "Duplicate entry" or INSERT fails
```
Error: UNIQUE constraint failed: urs_items.urs_code
```

**Solution:**
Use `--truncate` to replace all imported items:
```bash
node scripts/import_urs_catalog.mjs --from-csv data/urs_export.csv --truncate
```

### Issue 4: "No module xlsx"
```
Error: Failed to parse Excel: Cannot find module 'xlsx'
```

**Solution:**
Install xlsx dependency:
```bash
cd backend
npm install xlsx
```

---

## üìä Database Schema After Import

### `urs_items` Table
```sql
-- Before: 20 sample items (is_imported = 0)
-- After: 20 sample items + 5000+ imported items (is_imported = 1)

SELECT * FROM urs_items WHERE is_imported = 1 LIMIT 5;

-- Result:
-- id | urs_code   | urs_name                        | unit | section_code | ... | is_imported
-- 1  | 274313821  | Z√°kladov√© pasy z betonu C30/37  | m3   | 27           | ... | 1
-- 2  | 276313831  | Stƒõny z betonu C30/37           | m3   | 27           | ... | 1
-- 3  | 311234567  | Zdivo z p√°len√Ωch cihel          | m2   | 31           | ... | 1
-- ...
```

### Indexing
```sql
-- Fast lookups:
CREATE INDEX idx_urs_code ON urs_items(urs_code);
CREATE INDEX idx_urs_name ON urs_items(urs_name);
CREATE INDEX idx_urs_section_code ON urs_items(section_code);
CREATE INDEX idx_urs_is_imported ON urs_items(is_imported);
```

---

## üîê Legal/License Considerations

‚ö†Ô∏è **IMPORTANT:**
- Only import √öRS data from **official sources** or your own **licensed exports**
- Do not scrape podminky.urs.cz website (violates Terms of Use)
- Do not redistribute the catalog without permission
- Use only for internal project needs

**Recommended sources:**
- Your organization's KROS/√öRS account
- Publicly available exports with proper licensing
- Official ƒåKAIT distributions

---

## üìà Performance Notes

### Import Speed
- 5,000 items: ~10 seconds
- 20,000 items: ~40 seconds
- 40,000+ items: ~90 seconds

Bottleneck: SQLite transactions (single-threaded)

### Query Speed After Import
- Code lookup (indexed): < 1ms
- Name search (LIKE): 50-200ms
- Similarity search (all): 200-500ms

With proper indexes, very fast for typical BOQ matching.

---

## ‚úÖ Checklist After Import

- [ ] Import script ran without errors
- [ ] Database has 1000+ imported items
- [ ] Section breakdown shows diversity (27, 31, 32, 41, etc.)
- [ ] Sample items still exist (is_imported = 0)
- [ ] Test `/api/jobs/text-match` returns real catalog items
- [ ] `/api/jobs/block-match-fast` works with imported data
- [ ] Cache (kb_mappings) gets populated with real codes

---

## üöÄ Next Steps

After successful import:

1. **Deploy to Staging**
   - Copy urs_matcher.db with imported data
   - Test /block-match-fast endpoint
   - Verify response times (should be faster!)

2. **Monitor Performance**
   - Cache hit rates (should increase to 70-80%)
   - Perplexity usage (should decrease)
   - Response times (should be 5-10s)

3. **Maintain**
   - Update catalog quarterly (new codes)
   - Clean up obsolete mappings
   - Monitor database size

---

## üÜò Support

If import fails:

1. Check logs: `grep -i error backend/logs/*.log`
2. Verify file: `head -3 data/urs_export.csv`
3. Check database: `sqlite3 data/urs_matcher.db ".schema urs_items"`
4. Run with debug: `DEBUG=* node scripts/import_urs_catalog.mjs ...`

---

**Version:** 1.0
**Status:** ‚úÖ Ready for Production
**Created:** 2025-12-10
